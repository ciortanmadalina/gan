{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import random\n",
    "import itertools\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.collections\n",
    "from matplotlib import gridspec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import *\n",
    "\n",
    "import keras\n",
    "from keras.applications import *\n",
    "import lightgbm as lgbm\n",
    "from scipy import stats\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import * #Dense, Dropout, Activation, Flatten, Input,Concatenate, concatenate\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import cv2 as cv\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy import misc\n",
    "from keras.optimizers import Adam\n",
    "import copy, numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://math.stackexchange.com/questions/78575/derivative-of-sigmoid-function-sigma-x-frac11e-x\n",
    "# convert output of sigmoid function to its derivative\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-3, 3, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1754eaff748>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAEbCAYAAADZIELZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1755023ff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = plt.subplot(2,2,1)\n",
    "ax.plot(x, sigmoid(x))\n",
    "\n",
    "plt.axhline(1, color='grey', alpha=0.3)\n",
    "# plt.axvline(0, color='grey', alpha=0.3)\n",
    "\n",
    "ax.spines['left'].set_position('zero')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['bottom'].set_position('zero')\n",
    "ax.spines['top'].set_color('none')\n",
    "# ax.spines['left'].set_smart_bounds(True)\n",
    "# ax.spines['bottom'].set_smart_bounds(True)\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "plt.ylim(-1,2)\n",
    "plt.xlim(-10, 10)\n",
    "plt.title('Sigmoid')\n",
    "\n",
    "\n",
    "ax = plt.subplot(2,2,2)\n",
    "ax.plot(x, sigmoid_output_to_derivative(x))\n",
    "plt.title('Derivative of sigmoid')\n",
    "ax.spines['left'].set_position('center')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['bottom'].set_position('center')\n",
    "ax.spines['top'].set_color('none')\n",
    "plt.ylim(ymax = 2)\n",
    "plt.xlim(-10, 10)\n",
    "plt.axhline(0, color='grey', alpha=0.3, linewidth=1, linestyle = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training dataset generation\n",
    "int2binary = {}\n",
    "binary_dim = 8\n",
    "largest_number = pow(2,binary_dim)\n",
    "largest_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]], dtype=uint8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([range(largest_number)],dtype=np.uint8).T\n",
    "x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unpackbits(np.array([3], dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ..., \n",
       "       [1, 1, 1, ..., 1, 0, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary = np.unpackbits( np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "print(len(binary[0]))\n",
    "binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       " 1: array([0, 0, 0, 0, 0, 0, 0, 1], dtype=uint8),\n",
       " 2: array([0, 0, 0, 0, 0, 0, 1, 0], dtype=uint8),\n",
       " 3: array([0, 0, 0, 0, 0, 0, 1, 1], dtype=uint8),\n",
       " 4: array([0, 0, 0, 0, 0, 1, 0, 0], dtype=uint8),\n",
       " 5: array([0, 0, 0, 0, 0, 1, 0, 1], dtype=uint8),\n",
       " 6: array([0, 0, 0, 0, 0, 1, 1, 0], dtype=uint8),\n",
       " 7: array([0, 0, 0, 0, 0, 1, 1, 1], dtype=uint8),\n",
       " 8: array([0, 0, 0, 0, 1, 0, 0, 0], dtype=uint8),\n",
       " 9: array([0, 0, 0, 0, 1, 0, 0, 1], dtype=uint8),\n",
       " 10: array([0, 0, 0, 0, 1, 0, 1, 0], dtype=uint8),\n",
       " 11: array([0, 0, 0, 0, 1, 0, 1, 1], dtype=uint8),\n",
       " 12: array([0, 0, 0, 0, 1, 1, 0, 0], dtype=uint8),\n",
       " 13: array([0, 0, 0, 0, 1, 1, 0, 1], dtype=uint8),\n",
       " 14: array([0, 0, 0, 0, 1, 1, 1, 0], dtype=uint8),\n",
       " 15: array([0, 0, 0, 0, 1, 1, 1, 1], dtype=uint8),\n",
       " 16: array([0, 0, 0, 1, 0, 0, 0, 0], dtype=uint8),\n",
       " 17: array([0, 0, 0, 1, 0, 0, 0, 1], dtype=uint8),\n",
       " 18: array([0, 0, 0, 1, 0, 0, 1, 0], dtype=uint8),\n",
       " 19: array([0, 0, 0, 1, 0, 0, 1, 1], dtype=uint8),\n",
       " 20: array([0, 0, 0, 1, 0, 1, 0, 0], dtype=uint8),\n",
       " 21: array([0, 0, 0, 1, 0, 1, 0, 1], dtype=uint8),\n",
       " 22: array([0, 0, 0, 1, 0, 1, 1, 0], dtype=uint8),\n",
       " 23: array([0, 0, 0, 1, 0, 1, 1, 1], dtype=uint8),\n",
       " 24: array([0, 0, 0, 1, 1, 0, 0, 0], dtype=uint8),\n",
       " 25: array([0, 0, 0, 1, 1, 0, 0, 1], dtype=uint8),\n",
       " 26: array([0, 0, 0, 1, 1, 0, 1, 0], dtype=uint8),\n",
       " 27: array([0, 0, 0, 1, 1, 0, 1, 1], dtype=uint8),\n",
       " 28: array([0, 0, 0, 1, 1, 1, 0, 0], dtype=uint8),\n",
       " 29: array([0, 0, 0, 1, 1, 1, 0, 1], dtype=uint8),\n",
       " 30: array([0, 0, 0, 1, 1, 1, 1, 0], dtype=uint8),\n",
       " 31: array([0, 0, 0, 1, 1, 1, 1, 1], dtype=uint8),\n",
       " 32: array([0, 0, 1, 0, 0, 0, 0, 0], dtype=uint8),\n",
       " 33: array([0, 0, 1, 0, 0, 0, 0, 1], dtype=uint8),\n",
       " 34: array([0, 0, 1, 0, 0, 0, 1, 0], dtype=uint8),\n",
       " 35: array([0, 0, 1, 0, 0, 0, 1, 1], dtype=uint8),\n",
       " 36: array([0, 0, 1, 0, 0, 1, 0, 0], dtype=uint8),\n",
       " 37: array([0, 0, 1, 0, 0, 1, 0, 1], dtype=uint8),\n",
       " 38: array([0, 0, 1, 0, 0, 1, 1, 0], dtype=uint8),\n",
       " 39: array([0, 0, 1, 0, 0, 1, 1, 1], dtype=uint8),\n",
       " 40: array([0, 0, 1, 0, 1, 0, 0, 0], dtype=uint8),\n",
       " 41: array([0, 0, 1, 0, 1, 0, 0, 1], dtype=uint8),\n",
       " 42: array([0, 0, 1, 0, 1, 0, 1, 0], dtype=uint8),\n",
       " 43: array([0, 0, 1, 0, 1, 0, 1, 1], dtype=uint8),\n",
       " 44: array([0, 0, 1, 0, 1, 1, 0, 0], dtype=uint8),\n",
       " 45: array([0, 0, 1, 0, 1, 1, 0, 1], dtype=uint8),\n",
       " 46: array([0, 0, 1, 0, 1, 1, 1, 0], dtype=uint8),\n",
       " 47: array([0, 0, 1, 0, 1, 1, 1, 1], dtype=uint8),\n",
       " 48: array([0, 0, 1, 1, 0, 0, 0, 0], dtype=uint8),\n",
       " 49: array([0, 0, 1, 1, 0, 0, 0, 1], dtype=uint8),\n",
       " 50: array([0, 0, 1, 1, 0, 0, 1, 0], dtype=uint8),\n",
       " 51: array([0, 0, 1, 1, 0, 0, 1, 1], dtype=uint8),\n",
       " 52: array([0, 0, 1, 1, 0, 1, 0, 0], dtype=uint8),\n",
       " 53: array([0, 0, 1, 1, 0, 1, 0, 1], dtype=uint8),\n",
       " 54: array([0, 0, 1, 1, 0, 1, 1, 0], dtype=uint8),\n",
       " 55: array([0, 0, 1, 1, 0, 1, 1, 1], dtype=uint8),\n",
       " 56: array([0, 0, 1, 1, 1, 0, 0, 0], dtype=uint8),\n",
       " 57: array([0, 0, 1, 1, 1, 0, 0, 1], dtype=uint8),\n",
       " 58: array([0, 0, 1, 1, 1, 0, 1, 0], dtype=uint8),\n",
       " 59: array([0, 0, 1, 1, 1, 0, 1, 1], dtype=uint8),\n",
       " 60: array([0, 0, 1, 1, 1, 1, 0, 0], dtype=uint8),\n",
       " 61: array([0, 0, 1, 1, 1, 1, 0, 1], dtype=uint8),\n",
       " 62: array([0, 0, 1, 1, 1, 1, 1, 0], dtype=uint8),\n",
       " 63: array([0, 0, 1, 1, 1, 1, 1, 1], dtype=uint8),\n",
       " 64: array([0, 1, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       " 65: array([0, 1, 0, 0, 0, 0, 0, 1], dtype=uint8),\n",
       " 66: array([0, 1, 0, 0, 0, 0, 1, 0], dtype=uint8),\n",
       " 67: array([0, 1, 0, 0, 0, 0, 1, 1], dtype=uint8),\n",
       " 68: array([0, 1, 0, 0, 0, 1, 0, 0], dtype=uint8),\n",
       " 69: array([0, 1, 0, 0, 0, 1, 0, 1], dtype=uint8),\n",
       " 70: array([0, 1, 0, 0, 0, 1, 1, 0], dtype=uint8),\n",
       " 71: array([0, 1, 0, 0, 0, 1, 1, 1], dtype=uint8),\n",
       " 72: array([0, 1, 0, 0, 1, 0, 0, 0], dtype=uint8),\n",
       " 73: array([0, 1, 0, 0, 1, 0, 0, 1], dtype=uint8),\n",
       " 74: array([0, 1, 0, 0, 1, 0, 1, 0], dtype=uint8),\n",
       " 75: array([0, 1, 0, 0, 1, 0, 1, 1], dtype=uint8),\n",
       " 76: array([0, 1, 0, 0, 1, 1, 0, 0], dtype=uint8),\n",
       " 77: array([0, 1, 0, 0, 1, 1, 0, 1], dtype=uint8),\n",
       " 78: array([0, 1, 0, 0, 1, 1, 1, 0], dtype=uint8),\n",
       " 79: array([0, 1, 0, 0, 1, 1, 1, 1], dtype=uint8),\n",
       " 80: array([0, 1, 0, 1, 0, 0, 0, 0], dtype=uint8),\n",
       " 81: array([0, 1, 0, 1, 0, 0, 0, 1], dtype=uint8),\n",
       " 82: array([0, 1, 0, 1, 0, 0, 1, 0], dtype=uint8),\n",
       " 83: array([0, 1, 0, 1, 0, 0, 1, 1], dtype=uint8),\n",
       " 84: array([0, 1, 0, 1, 0, 1, 0, 0], dtype=uint8),\n",
       " 85: array([0, 1, 0, 1, 0, 1, 0, 1], dtype=uint8),\n",
       " 86: array([0, 1, 0, 1, 0, 1, 1, 0], dtype=uint8),\n",
       " 87: array([0, 1, 0, 1, 0, 1, 1, 1], dtype=uint8),\n",
       " 88: array([0, 1, 0, 1, 1, 0, 0, 0], dtype=uint8),\n",
       " 89: array([0, 1, 0, 1, 1, 0, 0, 1], dtype=uint8),\n",
       " 90: array([0, 1, 0, 1, 1, 0, 1, 0], dtype=uint8),\n",
       " 91: array([0, 1, 0, 1, 1, 0, 1, 1], dtype=uint8),\n",
       " 92: array([0, 1, 0, 1, 1, 1, 0, 0], dtype=uint8),\n",
       " 93: array([0, 1, 0, 1, 1, 1, 0, 1], dtype=uint8),\n",
       " 94: array([0, 1, 0, 1, 1, 1, 1, 0], dtype=uint8),\n",
       " 95: array([0, 1, 0, 1, 1, 1, 1, 1], dtype=uint8),\n",
       " 96: array([0, 1, 1, 0, 0, 0, 0, 0], dtype=uint8),\n",
       " 97: array([0, 1, 1, 0, 0, 0, 0, 1], dtype=uint8),\n",
       " 98: array([0, 1, 1, 0, 0, 0, 1, 0], dtype=uint8),\n",
       " 99: array([0, 1, 1, 0, 0, 0, 1, 1], dtype=uint8),\n",
       " 100: array([0, 1, 1, 0, 0, 1, 0, 0], dtype=uint8),\n",
       " 101: array([0, 1, 1, 0, 0, 1, 0, 1], dtype=uint8),\n",
       " 102: array([0, 1, 1, 0, 0, 1, 1, 0], dtype=uint8),\n",
       " 103: array([0, 1, 1, 0, 0, 1, 1, 1], dtype=uint8),\n",
       " 104: array([0, 1, 1, 0, 1, 0, 0, 0], dtype=uint8),\n",
       " 105: array([0, 1, 1, 0, 1, 0, 0, 1], dtype=uint8),\n",
       " 106: array([0, 1, 1, 0, 1, 0, 1, 0], dtype=uint8),\n",
       " 107: array([0, 1, 1, 0, 1, 0, 1, 1], dtype=uint8),\n",
       " 108: array([0, 1, 1, 0, 1, 1, 0, 0], dtype=uint8),\n",
       " 109: array([0, 1, 1, 0, 1, 1, 0, 1], dtype=uint8),\n",
       " 110: array([0, 1, 1, 0, 1, 1, 1, 0], dtype=uint8),\n",
       " 111: array([0, 1, 1, 0, 1, 1, 1, 1], dtype=uint8),\n",
       " 112: array([0, 1, 1, 1, 0, 0, 0, 0], dtype=uint8),\n",
       " 113: array([0, 1, 1, 1, 0, 0, 0, 1], dtype=uint8),\n",
       " 114: array([0, 1, 1, 1, 0, 0, 1, 0], dtype=uint8),\n",
       " 115: array([0, 1, 1, 1, 0, 0, 1, 1], dtype=uint8),\n",
       " 116: array([0, 1, 1, 1, 0, 1, 0, 0], dtype=uint8),\n",
       " 117: array([0, 1, 1, 1, 0, 1, 0, 1], dtype=uint8),\n",
       " 118: array([0, 1, 1, 1, 0, 1, 1, 0], dtype=uint8),\n",
       " 119: array([0, 1, 1, 1, 0, 1, 1, 1], dtype=uint8),\n",
       " 120: array([0, 1, 1, 1, 1, 0, 0, 0], dtype=uint8),\n",
       " 121: array([0, 1, 1, 1, 1, 0, 0, 1], dtype=uint8),\n",
       " 122: array([0, 1, 1, 1, 1, 0, 1, 0], dtype=uint8),\n",
       " 123: array([0, 1, 1, 1, 1, 0, 1, 1], dtype=uint8),\n",
       " 124: array([0, 1, 1, 1, 1, 1, 0, 0], dtype=uint8),\n",
       " 125: array([0, 1, 1, 1, 1, 1, 0, 1], dtype=uint8),\n",
       " 126: array([0, 1, 1, 1, 1, 1, 1, 0], dtype=uint8),\n",
       " 127: array([0, 1, 1, 1, 1, 1, 1, 1], dtype=uint8),\n",
       " 128: array([1, 0, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       " 129: array([1, 0, 0, 0, 0, 0, 0, 1], dtype=uint8),\n",
       " 130: array([1, 0, 0, 0, 0, 0, 1, 0], dtype=uint8),\n",
       " 131: array([1, 0, 0, 0, 0, 0, 1, 1], dtype=uint8),\n",
       " 132: array([1, 0, 0, 0, 0, 1, 0, 0], dtype=uint8),\n",
       " 133: array([1, 0, 0, 0, 0, 1, 0, 1], dtype=uint8),\n",
       " 134: array([1, 0, 0, 0, 0, 1, 1, 0], dtype=uint8),\n",
       " 135: array([1, 0, 0, 0, 0, 1, 1, 1], dtype=uint8),\n",
       " 136: array([1, 0, 0, 0, 1, 0, 0, 0], dtype=uint8),\n",
       " 137: array([1, 0, 0, 0, 1, 0, 0, 1], dtype=uint8),\n",
       " 138: array([1, 0, 0, 0, 1, 0, 1, 0], dtype=uint8),\n",
       " 139: array([1, 0, 0, 0, 1, 0, 1, 1], dtype=uint8),\n",
       " 140: array([1, 0, 0, 0, 1, 1, 0, 0], dtype=uint8),\n",
       " 141: array([1, 0, 0, 0, 1, 1, 0, 1], dtype=uint8),\n",
       " 142: array([1, 0, 0, 0, 1, 1, 1, 0], dtype=uint8),\n",
       " 143: array([1, 0, 0, 0, 1, 1, 1, 1], dtype=uint8),\n",
       " 144: array([1, 0, 0, 1, 0, 0, 0, 0], dtype=uint8),\n",
       " 145: array([1, 0, 0, 1, 0, 0, 0, 1], dtype=uint8),\n",
       " 146: array([1, 0, 0, 1, 0, 0, 1, 0], dtype=uint8),\n",
       " 147: array([1, 0, 0, 1, 0, 0, 1, 1], dtype=uint8),\n",
       " 148: array([1, 0, 0, 1, 0, 1, 0, 0], dtype=uint8),\n",
       " 149: array([1, 0, 0, 1, 0, 1, 0, 1], dtype=uint8),\n",
       " 150: array([1, 0, 0, 1, 0, 1, 1, 0], dtype=uint8),\n",
       " 151: array([1, 0, 0, 1, 0, 1, 1, 1], dtype=uint8),\n",
       " 152: array([1, 0, 0, 1, 1, 0, 0, 0], dtype=uint8),\n",
       " 153: array([1, 0, 0, 1, 1, 0, 0, 1], dtype=uint8),\n",
       " 154: array([1, 0, 0, 1, 1, 0, 1, 0], dtype=uint8),\n",
       " 155: array([1, 0, 0, 1, 1, 0, 1, 1], dtype=uint8),\n",
       " 156: array([1, 0, 0, 1, 1, 1, 0, 0], dtype=uint8),\n",
       " 157: array([1, 0, 0, 1, 1, 1, 0, 1], dtype=uint8),\n",
       " 158: array([1, 0, 0, 1, 1, 1, 1, 0], dtype=uint8),\n",
       " 159: array([1, 0, 0, 1, 1, 1, 1, 1], dtype=uint8),\n",
       " 160: array([1, 0, 1, 0, 0, 0, 0, 0], dtype=uint8),\n",
       " 161: array([1, 0, 1, 0, 0, 0, 0, 1], dtype=uint8),\n",
       " 162: array([1, 0, 1, 0, 0, 0, 1, 0], dtype=uint8),\n",
       " 163: array([1, 0, 1, 0, 0, 0, 1, 1], dtype=uint8),\n",
       " 164: array([1, 0, 1, 0, 0, 1, 0, 0], dtype=uint8),\n",
       " 165: array([1, 0, 1, 0, 0, 1, 0, 1], dtype=uint8),\n",
       " 166: array([1, 0, 1, 0, 0, 1, 1, 0], dtype=uint8),\n",
       " 167: array([1, 0, 1, 0, 0, 1, 1, 1], dtype=uint8),\n",
       " 168: array([1, 0, 1, 0, 1, 0, 0, 0], dtype=uint8),\n",
       " 169: array([1, 0, 1, 0, 1, 0, 0, 1], dtype=uint8),\n",
       " 170: array([1, 0, 1, 0, 1, 0, 1, 0], dtype=uint8),\n",
       " 171: array([1, 0, 1, 0, 1, 0, 1, 1], dtype=uint8),\n",
       " 172: array([1, 0, 1, 0, 1, 1, 0, 0], dtype=uint8),\n",
       " 173: array([1, 0, 1, 0, 1, 1, 0, 1], dtype=uint8),\n",
       " 174: array([1, 0, 1, 0, 1, 1, 1, 0], dtype=uint8),\n",
       " 175: array([1, 0, 1, 0, 1, 1, 1, 1], dtype=uint8),\n",
       " 176: array([1, 0, 1, 1, 0, 0, 0, 0], dtype=uint8),\n",
       " 177: array([1, 0, 1, 1, 0, 0, 0, 1], dtype=uint8),\n",
       " 178: array([1, 0, 1, 1, 0, 0, 1, 0], dtype=uint8),\n",
       " 179: array([1, 0, 1, 1, 0, 0, 1, 1], dtype=uint8),\n",
       " 180: array([1, 0, 1, 1, 0, 1, 0, 0], dtype=uint8),\n",
       " 181: array([1, 0, 1, 1, 0, 1, 0, 1], dtype=uint8),\n",
       " 182: array([1, 0, 1, 1, 0, 1, 1, 0], dtype=uint8),\n",
       " 183: array([1, 0, 1, 1, 0, 1, 1, 1], dtype=uint8),\n",
       " 184: array([1, 0, 1, 1, 1, 0, 0, 0], dtype=uint8),\n",
       " 185: array([1, 0, 1, 1, 1, 0, 0, 1], dtype=uint8),\n",
       " 186: array([1, 0, 1, 1, 1, 0, 1, 0], dtype=uint8),\n",
       " 187: array([1, 0, 1, 1, 1, 0, 1, 1], dtype=uint8),\n",
       " 188: array([1, 0, 1, 1, 1, 1, 0, 0], dtype=uint8),\n",
       " 189: array([1, 0, 1, 1, 1, 1, 0, 1], dtype=uint8),\n",
       " 190: array([1, 0, 1, 1, 1, 1, 1, 0], dtype=uint8),\n",
       " 191: array([1, 0, 1, 1, 1, 1, 1, 1], dtype=uint8),\n",
       " 192: array([1, 1, 0, 0, 0, 0, 0, 0], dtype=uint8),\n",
       " 193: array([1, 1, 0, 0, 0, 0, 0, 1], dtype=uint8),\n",
       " 194: array([1, 1, 0, 0, 0, 0, 1, 0], dtype=uint8),\n",
       " 195: array([1, 1, 0, 0, 0, 0, 1, 1], dtype=uint8),\n",
       " 196: array([1, 1, 0, 0, 0, 1, 0, 0], dtype=uint8),\n",
       " 197: array([1, 1, 0, 0, 0, 1, 0, 1], dtype=uint8),\n",
       " 198: array([1, 1, 0, 0, 0, 1, 1, 0], dtype=uint8),\n",
       " 199: array([1, 1, 0, 0, 0, 1, 1, 1], dtype=uint8),\n",
       " 200: array([1, 1, 0, 0, 1, 0, 0, 0], dtype=uint8),\n",
       " 201: array([1, 1, 0, 0, 1, 0, 0, 1], dtype=uint8),\n",
       " 202: array([1, 1, 0, 0, 1, 0, 1, 0], dtype=uint8),\n",
       " 203: array([1, 1, 0, 0, 1, 0, 1, 1], dtype=uint8),\n",
       " 204: array([1, 1, 0, 0, 1, 1, 0, 0], dtype=uint8),\n",
       " 205: array([1, 1, 0, 0, 1, 1, 0, 1], dtype=uint8),\n",
       " 206: array([1, 1, 0, 0, 1, 1, 1, 0], dtype=uint8),\n",
       " 207: array([1, 1, 0, 0, 1, 1, 1, 1], dtype=uint8),\n",
       " 208: array([1, 1, 0, 1, 0, 0, 0, 0], dtype=uint8),\n",
       " 209: array([1, 1, 0, 1, 0, 0, 0, 1], dtype=uint8),\n",
       " 210: array([1, 1, 0, 1, 0, 0, 1, 0], dtype=uint8),\n",
       " 211: array([1, 1, 0, 1, 0, 0, 1, 1], dtype=uint8),\n",
       " 212: array([1, 1, 0, 1, 0, 1, 0, 0], dtype=uint8),\n",
       " 213: array([1, 1, 0, 1, 0, 1, 0, 1], dtype=uint8),\n",
       " 214: array([1, 1, 0, 1, 0, 1, 1, 0], dtype=uint8),\n",
       " 215: array([1, 1, 0, 1, 0, 1, 1, 1], dtype=uint8),\n",
       " 216: array([1, 1, 0, 1, 1, 0, 0, 0], dtype=uint8),\n",
       " 217: array([1, 1, 0, 1, 1, 0, 0, 1], dtype=uint8),\n",
       " 218: array([1, 1, 0, 1, 1, 0, 1, 0], dtype=uint8),\n",
       " 219: array([1, 1, 0, 1, 1, 0, 1, 1], dtype=uint8),\n",
       " 220: array([1, 1, 0, 1, 1, 1, 0, 0], dtype=uint8),\n",
       " 221: array([1, 1, 0, 1, 1, 1, 0, 1], dtype=uint8),\n",
       " 222: array([1, 1, 0, 1, 1, 1, 1, 0], dtype=uint8),\n",
       " 223: array([1, 1, 0, 1, 1, 1, 1, 1], dtype=uint8),\n",
       " 224: array([1, 1, 1, 0, 0, 0, 0, 0], dtype=uint8),\n",
       " 225: array([1, 1, 1, 0, 0, 0, 0, 1], dtype=uint8),\n",
       " 226: array([1, 1, 1, 0, 0, 0, 1, 0], dtype=uint8),\n",
       " 227: array([1, 1, 1, 0, 0, 0, 1, 1], dtype=uint8),\n",
       " 228: array([1, 1, 1, 0, 0, 1, 0, 0], dtype=uint8),\n",
       " 229: array([1, 1, 1, 0, 0, 1, 0, 1], dtype=uint8),\n",
       " 230: array([1, 1, 1, 0, 0, 1, 1, 0], dtype=uint8),\n",
       " 231: array([1, 1, 1, 0, 0, 1, 1, 1], dtype=uint8),\n",
       " 232: array([1, 1, 1, 0, 1, 0, 0, 0], dtype=uint8),\n",
       " 233: array([1, 1, 1, 0, 1, 0, 0, 1], dtype=uint8),\n",
       " 234: array([1, 1, 1, 0, 1, 0, 1, 0], dtype=uint8),\n",
       " 235: array([1, 1, 1, 0, 1, 0, 1, 1], dtype=uint8),\n",
       " 236: array([1, 1, 1, 0, 1, 1, 0, 0], dtype=uint8),\n",
       " 237: array([1, 1, 1, 0, 1, 1, 0, 1], dtype=uint8),\n",
       " 238: array([1, 1, 1, 0, 1, 1, 1, 0], dtype=uint8),\n",
       " 239: array([1, 1, 1, 0, 1, 1, 1, 1], dtype=uint8),\n",
       " 240: array([1, 1, 1, 1, 0, 0, 0, 0], dtype=uint8),\n",
       " 241: array([1, 1, 1, 1, 0, 0, 0, 1], dtype=uint8),\n",
       " 242: array([1, 1, 1, 1, 0, 0, 1, 0], dtype=uint8),\n",
       " 243: array([1, 1, 1, 1, 0, 0, 1, 1], dtype=uint8),\n",
       " 244: array([1, 1, 1, 1, 0, 1, 0, 0], dtype=uint8),\n",
       " 245: array([1, 1, 1, 1, 0, 1, 0, 1], dtype=uint8),\n",
       " 246: array([1, 1, 1, 1, 0, 1, 1, 0], dtype=uint8),\n",
       " 247: array([1, 1, 1, 1, 0, 1, 1, 1], dtype=uint8),\n",
       " 248: array([1, 1, 1, 1, 1, 0, 0, 0], dtype=uint8),\n",
       " 249: array([1, 1, 1, 1, 1, 0, 0, 1], dtype=uint8),\n",
       " 250: array([1, 1, 1, 1, 1, 0, 1, 0], dtype=uint8),\n",
       " 251: array([1, 1, 1, 1, 1, 0, 1, 1], dtype=uint8),\n",
       " 252: array([1, 1, 1, 1, 1, 1, 0, 0], dtype=uint8),\n",
       " 253: array([1, 1, 1, 1, 1, 1, 0, 1], dtype=uint8),\n",
       " 254: array([1, 1, 1, 1, 1, 1, 1, 0], dtype=uint8),\n",
       " 255: array([1, 1, 1, 1, 1, 1, 1, 1], dtype=uint8)}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]\n",
    "int2binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input variables\n",
    "alpha = 0.1\n",
    "input_dim = 2\n",
    "hidden_dim = 16\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60683528, -0.26254966,  0.64198646, -0.80579745,  0.67588981,\n",
       "        -0.80780318,  0.95291893, -0.0626976 ,  0.95352218,  0.20969104,\n",
       "         0.47852716, -0.92162442, -0.43438607, -0.75960688, -0.4077196 ,\n",
       "        -0.76254456],\n",
       "       [-0.36403364, -0.17147401, -0.87170501,  0.38494424,  0.13320291,\n",
       "        -0.46922102,  0.04649611, -0.81211898,  0.15189299,  0.8585924 ,\n",
       "        -0.3628621 ,  0.33482076, -0.73640428,  0.43265441, -0.42118781,\n",
       "        -0.63361728]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * np.random.random((input_dim,hidden_dim)) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize neural network weights\n",
    "synapse_0 = 2*np.random.random((input_dim,hidden_dim)) - 1 # 2, 16\n",
    "synapse_1 = 2*np.random.random((hidden_dim,output_dim)) - 1 # 16, 1\n",
    "synapse_h = 2*np.random.random((hidden_dim,hidden_dim)) - 1 # 16, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synapse_0_update = np.zeros_like(synapse_0)\n",
    "synapse_1_update = np.zeros_like(synapse_1)\n",
    "synapse_h_update = np.zeros_like(synapse_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =  [0 1 0 0 1 1 0 1]  b =  [0 0 0 1 0 1 0 1]  c =  [0 1 1 0 0 0 1 0]  d =  [0 0 0 0 0 0 0 0]\n",
      "layer_1_values  [array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.])]\n",
      "X =  [[1 1]] y =  [[0]]\n",
      "layer_1  [[ 0.63922094  0.20344329  0.78338042  0.23190287  0.75358774  0.42618383\n",
      "   0.77449324  0.78741948  0.48700664  0.53866352  0.74955702  0.60646672\n",
      "   0.33045528  0.75367036  0.25590492  0.57345632]]\n",
      "layer_2  [[ 0.65988251]]\n",
      "layer_2_error  [[-0.65988251]]  overallError  [ 0.65988251]\n",
      "X =  [[0 0]] y =  [[1]]\n",
      "layer_1  [[ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      "   0.5  0.5]]\n",
      "layer_2  [[ 0.62118332]]\n",
      "layer_2_error  [[ 0.37881668]]  overallError  [ 1.03869919]\n",
      "X =  [[1 1]] y =  [[0]]\n",
      "layer_1  [[ 0.63922094  0.20344329  0.78338042  0.23190287  0.75358774  0.42618383\n",
      "   0.77449324  0.78741948  0.48700664  0.53866352  0.74955702  0.60646672\n",
      "   0.33045528  0.75367036  0.25590492  0.57345632]]\n",
      "layer_2  [[ 0.65988251]]\n",
      "layer_2_error  [[-0.65988251]]  overallError  [ 1.69858169]\n",
      "X =  [[1 0]] y =  [[0]]\n",
      "layer_1  [[ 0.54314887  0.27692126  0.65878401  0.2707918   0.58798291  0.38698961\n",
      "   0.6154756   0.71593313  0.37695482  0.53800522  0.54589145  0.53606322\n",
      "   0.36497472  0.71207804  0.4735873   0.66659337]]\n",
      "layer_2  [[ 0.66421074]]\n",
      "layer_2_error  [[-0.66421074]]  overallError  [ 2.36279243]\n",
      "X =  [[0 1]] y =  [[0]]\n",
      "layer_1  [[ 0.59843742  0.40008137  0.65194408  0.44843684  0.68183257  0.5405472\n",
      "   0.68210679  0.5950937   0.61076014  0.50066219  0.71344345  0.57150163\n",
      "   0.46200094  0.55299679  0.27655524  0.40206931]]\n",
      "layer_2  [[ 0.61883924]]\n",
      "layer_2_error  [[-0.61883924]]  overallError  [ 2.98163167]\n",
      "X =  [[0 0]] y =  [[1]]\n",
      "layer_1  [[ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      "   0.5  0.5]]\n",
      "layer_2  [[ 0.62118332]]\n",
      "layer_2_error  [[ 0.37881668]]  overallError  [ 3.36044835]\n",
      "X =  [[1 0]] y =  [[1]]\n",
      "layer_1  [[ 0.54314887  0.27692126  0.65878401  0.2707918   0.58798291  0.38698961\n",
      "   0.6154756   0.71593313  0.37695482  0.53800522  0.54589145  0.53606322\n",
      "   0.36497472  0.71207804  0.4735873   0.66659337]]\n",
      "layer_2  [[ 0.66421074]]\n",
      "layer_2_error  [[ 0.33578926]]  overallError  [ 3.69623761]\n",
      "X =  [[0 0]] y =  [[0]]\n",
      "layer_1  [[ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      "   0.5  0.5]]\n",
      "layer_2  [[ 0.62118332]]\n",
      "layer_2_error  [[-0.62118332]]  overallError  [ 4.31742093]\n",
      "a =  [0 1 1 1 1 0 1 1]  b =  [0 0 0 1 1 1 1 1]  c =  [1 0 0 1 1 0 1 0]  d =  [0 0 0 0 0 0 0 0]\n",
      "layer_1_values  [array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.])]\n",
      "X =  [[1 1]] y =  [[0]]\n",
      "layer_1  [[ 0.63922094  0.20344329  0.78338042  0.23190287  0.75358774  0.42618383\n",
      "   0.77449324  0.78741948  0.48700664  0.53866352  0.74955702  0.60646672\n",
      "   0.33045528  0.75367036  0.25590492  0.57345632]]\n",
      "layer_2  [[ 0.65988251]]\n",
      "layer_2_error  [[-0.65988251]]  overallError  [ 0.65988251]\n",
      "X =  [[1 1]] y =  [[1]]\n",
      "layer_1  [[ 0.63922094  0.20344329  0.78338042  0.23190287  0.75358774  0.42618383\n",
      "   0.77449324  0.78741948  0.48700664  0.53866352  0.74955702  0.60646672\n",
      "   0.33045528  0.75367036  0.25590492  0.57345632]]\n",
      "layer_2  [[ 0.65988251]]\n",
      "layer_2_error  [[ 0.34011749]]  overallError  [ 1.]\n",
      "X =  [[0 1]] y =  [[0]]\n",
      "layer_1  [[ 0.59843742  0.40008137  0.65194408  0.44843684  0.68183257  0.5405472\n",
      "   0.68210679  0.5950937   0.61076014  0.50066219  0.71344345  0.57150163\n",
      "   0.46200094  0.55299679  0.27655524  0.40206931]]\n",
      "layer_2  [[ 0.61883924]]\n",
      "layer_2_error  [[-0.61883924]]  overallError  [ 1.61883924]\n",
      "X =  [[1 1]] y =  [[1]]\n",
      "layer_1  [[ 0.63922094  0.20344329  0.78338042  0.23190287  0.75358774  0.42618383\n",
      "   0.77449324  0.78741948  0.48700664  0.53866352  0.74955702  0.60646672\n",
      "   0.33045528  0.75367036  0.25590492  0.57345632]]\n",
      "layer_2  [[ 0.65988251]]\n",
      "layer_2_error  [[ 0.34011749]]  overallError  [ 1.95895673]\n",
      "X =  [[1 1]] y =  [[1]]\n",
      "layer_1  [[ 0.63922094  0.20344329  0.78338042  0.23190287  0.75358774  0.42618383\n",
      "   0.77449324  0.78741948  0.48700664  0.53866352  0.74955702  0.60646672\n",
      "   0.33045528  0.75367036  0.25590492  0.57345632]]\n",
      "layer_2  [[ 0.65988251]]\n",
      "layer_2_error  [[ 0.34011749]]  overallError  [ 2.29907422]\n",
      "X =  [[1 0]] y =  [[0]]\n",
      "layer_1  [[ 0.54314887  0.27692126  0.65878401  0.2707918   0.58798291  0.38698961\n",
      "   0.6154756   0.71593313  0.37695482  0.53800522  0.54589145  0.53606322\n",
      "   0.36497472  0.71207804  0.4735873   0.66659337]]\n",
      "layer_2  [[ 0.66421074]]\n",
      "layer_2_error  [[-0.66421074]]  overallError  [ 2.96328496]\n",
      "X =  [[1 0]] y =  [[0]]\n",
      "layer_1  [[ 0.54314887  0.27692126  0.65878401  0.2707918   0.58798291  0.38698961\n",
      "   0.6154756   0.71593313  0.37695482  0.53800522  0.54589145  0.53606322\n",
      "   0.36497472  0.71207804  0.4735873   0.66659337]]\n",
      "layer_2  [[ 0.66421074]]\n",
      "layer_2_error  [[-0.66421074]]  overallError  [ 3.6274957]\n",
      "X =  [[0 0]] y =  [[1]]\n",
      "layer_1  [[ 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      "   0.5  0.5]]\n",
      "layer_2  [[ 0.62118332]]\n",
      "layer_2_error  [[ 0.37881668]]  overallError  [ 4.00631237]\n"
     ]
    }
   ],
   "source": [
    "# training logic\n",
    "for j in range(2):\n",
    "    \n",
    "    # generate a simple addition problem (a + b = c)\n",
    "    a_int = np.random.randint(largest_number/2) # int version\n",
    "    a = int2binary[a_int] # binary encoding\n",
    "    \n",
    "\n",
    "    b_int = np.random.randint(largest_number/2) # int version\n",
    "    b = int2binary[b_int] # binary encoding\n",
    "\n",
    "    # true answer\n",
    "    c_int = a_int + b_int\n",
    "    c = int2binary[c_int]\n",
    "    \n",
    "    \n",
    "    # where we'll store our best guess (binary encoded)\n",
    "    d = np.zeros_like(c)\n",
    "    print('a = ', a , ' b = ', b , ' c = ', c, ' d = ', d)\n",
    "\n",
    "    overallError = 0\n",
    "    \n",
    "    layer_2_deltas = list()\n",
    "    layer_1_values = list()\n",
    "    layer_1_values.append(np.zeros(hidden_dim))\n",
    "    print('layer_1_values ', layer_1_values)\n",
    "    \n",
    "    # moving along the positions in the binary encoding\n",
    "    for position in range(binary_dim):\n",
    "        \n",
    "        # generate input and output\n",
    "        X = np.array([[a[binary_dim - position - 1],b[binary_dim - position - 1]]])\n",
    "        y = np.array([[c[binary_dim - position - 1]]]).T\n",
    "        print('X = ', X, 'y = ', y)\n",
    "#         print('synapse_0 ', synapse_0 , 'synapse_h ', synapse_h, ' layer_1_values[-1] = ', layer_1_values[-1])\n",
    "\n",
    "        # hidden layer (input ~+ prev_hidden)\n",
    "        layer_1 = sigmoid(np.dot(X,synapse_0) + np.dot(layer_1_values[-1],synapse_h))\n",
    "#         print('np.dot(X,synapse_0) ', np.dot(X,synapse_0))\n",
    "#         print(' np.dot(layer_1_values[-1],synapse_h) ', np.dot(layer_1_values[-1],synapse_h))\n",
    "#         print('sigmoid input = ', np.dot(X,synapse_0) + np.dot(layer_1_values[-1],synapse_h))\n",
    "        print('layer_1 ', layer_1)\n",
    "\n",
    "        # output layer (new binary representation)\n",
    "        layer_2 = sigmoid(np.dot(layer_1,synapse_1))\n",
    "        print('layer_2 ', layer_2)\n",
    "\n",
    "        # did we miss?... if so, by how much?\n",
    "        layer_2_error = y - layer_2\n",
    "        layer_2_deltas.append((layer_2_error)*sigmoid_output_to_derivative(layer_2))\n",
    "        overallError += np.abs(layer_2_error[0])\n",
    "        print('layer_2_error ', layer_2_error, ' overallError ', overallError)\n",
    "    \n",
    "        # decode estimate so we can print it out\n",
    "        d[binary_dim - position - 1] = np.round(layer_2[0][0])\n",
    "        \n",
    "        # store hidden layer so we can use it in the next timestep\n",
    "        layer_1_values.append(copy.deepcopy(layer_1))\n",
    "    \n",
    "    future_layer_1_delta = np.zeros(hidden_dim)\n",
    "    \n",
    "#     for position in range(binary_dim):\n",
    "        \n",
    "#         X = np.array([[a[position],b[position]]])\n",
    "#         layer_1 = layer_1_values[-position-1]\n",
    "#         prev_layer_1 = layer_1_values[-position-2]\n",
    "        \n",
    "#         # error at output layer\n",
    "#         layer_2_delta = layer_2_deltas[-position-1]\n",
    "#         # error at hidden layer\n",
    "#         layer_1_delta = (future_layer_1_delta.dot(synapse_h.T) + layer_2_delta.dot(synapse_1.T)) * sigmoid_output_to_derivative(layer_1)\n",
    "\n",
    "#         # let's update all our weights so we can try again\n",
    "#         synapse_1_update += np.atleast_2d(layer_1).T.dot(layer_2_delta)\n",
    "#         synapse_h_update += np.atleast_2d(prev_layer_1).T.dot(layer_1_delta)\n",
    "#         synapse_0_update += X.T.dot(layer_1_delta)\n",
    "        \n",
    "#         future_layer_1_delta = layer_1_delta\n",
    "    \n",
    "\n",
    "#     synapse_0 += synapse_0_update * alpha\n",
    "#     synapse_1 += synapse_1_update * alpha\n",
    "#     synapse_h += synapse_h_update * alpha    \n",
    "\n",
    "#     synapse_0_update *= 0\n",
    "#     synapse_1_update *= 0\n",
    "#     synapse_h_update *= 0\n",
    "    \n",
    "#     # print out progress\n",
    "#     if(j % 1000 == 0):\n",
    "#         print \"Error:\" + str(overallError)\n",
    "#         print \"Pred:\" + str(d)\n",
    "#         print \"True:\" + str(c)\n",
    "#         out = 0\n",
    "#         for index,x in enumerate(reversed(d)):\n",
    "#             out += x*pow(2,index)\n",
    "#         print str(a_int) + \" + \" + str(b_int) + \" = \" + str(out)\n",
    "#         print \"------------\"\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNeuralNetwork:\n",
    "    #input (word), expected output (next word), num of words (num of recurrences), array expected outputs, learning rate\n",
    "    def __init__ (self, xs, ys, rl, eo, lr):\n",
    "        #initial input (first word)\n",
    "        self.x = np.zeros(xs)\n",
    "        #input size \n",
    "        self.xs = xs\n",
    "        #expected output (next word)\n",
    "        self.y = np.zeros(ys)\n",
    "        #output size\n",
    "        self.ys = ys\n",
    "        #weight matrix for interpreting results from LSTM cell (num words x num words matrix)\n",
    "        self.w = np.random.random((ys, ys))\n",
    "        #matrix used in RMSprop\n",
    "        self.G = np.zeros_like(self.w)\n",
    "        #length of the recurrent network - number of recurrences i.e num of words\n",
    "        self.rl = rl\n",
    "        #learning rate \n",
    "        self.lr = lr\n",
    "        #array for storing inputs\n",
    "        self.ia = np.zeros((rl+1,xs))\n",
    "        #array for storing cell states\n",
    "        self.ca = np.zeros((rl+1,ys))\n",
    "        #array for storing outputs\n",
    "        self.oa = np.zeros((rl+1,ys))\n",
    "        #array for storing hidden states\n",
    "        self.ha = np.zeros((rl+1,ys))\n",
    "        #forget gate \n",
    "        self.af = np.zeros((rl+1,ys))\n",
    "        #input gate\n",
    "        self.ai = np.zeros((rl+1,ys))\n",
    "        #cell state\n",
    "        self.ac = np.zeros((rl+1,ys))\n",
    "        #output gate\n",
    "        self.ao = np.zeros((rl+1,ys))\n",
    "        #array of expected output values\n",
    "        self.eo = np.vstack((np.zeros(eo.shape[0]), eo.T))\n",
    "        #declare LSTM cell (input, output, amount of recurrence, learning rate)\n",
    "        self.LSTM = LSTM(xs, ys, rl, lr)\n",
    "    \n",
    "    #activation function. simple nonlinearity, convert nums into probabilities between 0 and 1\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    #the derivative of the sigmoid function. used to compute gradients for backpropagation\n",
    "    def dsigmoid(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))    \n",
    "    \n",
    "    #lets apply a series of matrix operations to our input (curr word) to compute a predicted output (next word)\n",
    "    def forwardProp(self):\n",
    "        for i in range(1, self.rl+1):\n",
    "            self.LSTM.x = np.hstack((self.ha[i-1], self.x))\n",
    "            cs, hs, f, c, o = self.LSTM.forwardProp()\n",
    "            #store computed cell state\n",
    "            self.ca[i] = cs\n",
    "            self.ha[i] = hs\n",
    "            self.af[i] = f\n",
    "            self.ai[i] = inp\n",
    "            self.ac[i] = c\n",
    "            self.ao[i] = o\n",
    "            #RRR\n",
    "            self.oa[i] = self.sigmoid(np.dot(self.w, hs))\n",
    "            self.x = self.eo[i-1]\n",
    "        return self.oa\n",
    "   \n",
    "    \n",
    "    def backProp(self):\n",
    "        #update our weight matrices (Both in our Recurrent network, as well as the weight matrices inside LSTM cell)\n",
    "        #init an empty error value \n",
    "        totalError = 0\n",
    "        #initialize matrices for gradient updates\n",
    "        #First, these are RNN level gradients\n",
    "        #cell state\n",
    "        dfcs = np.zeros(self.ys)\n",
    "        #hidden state,\n",
    "        dfhs = np.zeros(self.ys)\n",
    "        #weight matrix\n",
    "        tu = np.zeros((self.ys,self.ys))\n",
    "        #Next, these are LSTM level gradients\n",
    "        #forget gate\n",
    "        tfu = np.zeros((self.ys, self.xs+self.ys))\n",
    "        #input gate\n",
    "        tiu = np.zeros((self.ys, self.xs+self.ys))\n",
    "        #cell unit\n",
    "        tcu = np.zeros((self.ys, self.xs+self.ys))\n",
    "        #output gate\n",
    "        tou = np.zeros((self.ys, self.xs+self.ys))\n",
    "        #loop backwards through recurrences\n",
    "        for i in range(self.rl, -1, -1):\n",
    "            #error = calculatedOutput - expectedOutput\n",
    "            error = self.oa[i] - self.eo[i]\n",
    "            #calculate update for weight matrix\n",
    "            #(error * derivative of the output) * hidden state\n",
    "            tu += np.dot(np.atleast_2d(error * self.dsigmoid(self.oa[i])), np.atleast_2d(self.ha[i]).T)\n",
    "            #Time to propagate error back to exit of LSTM cell\n",
    "            #1. error * RNN weight matrix\n",
    "            error = np.dot(error, self.w)\n",
    "            #2. set input values of LSTM cell for recurrence i (horizontal stack of arrays, hidden + input)\n",
    "            self.LSTM.x = np.hstack((self.ha[i-1], self.ia[i]))\n",
    "            #3. set cell state of LSTM cell for recurrence i (pre-updates)\n",
    "            self.LSTM.cs = self.ca[i]\n",
    "            #Finally, call the LSTM cell's backprop, retreive gradient updates\n",
    "            #gradient updates for forget, input, cell unit, and output gates + cell states & hiddens states\n",
    "            fu, iu, cu, ou, dfcs, dfhs = self.LSTM.backProp(error, self.ca[i-1], self.af[i], self.ai[i], self.ac[i], self.ao[i], dfcs, dfhs)\n",
    "            #calculate total error (not necesarry, used to measure training progress)\n",
    "            totalError += np.sum(error)\n",
    "            #accumulate all gradient updates\n",
    "            #forget gate\n",
    "            tfu += fu\n",
    "            #input gate\n",
    "            tiu += iu\n",
    "            #cell state\n",
    "            tcu += cu\n",
    "            #output gate\n",
    "            tou += ou\n",
    "        #update LSTM matrices with average of accumulated gradient updates    \n",
    "        self.LSTM.update(tfu/self.rl, tiu/self.rl, tcu/self.rl, tou/self.rl) \n",
    "        #update weight matrix with average of accumulated gradient updates  \n",
    "        self.update(tu/self.rl)\n",
    "        #return total error of this iteration\n",
    "        return totalError\n",
    "    \n",
    "    def update(self, u):\n",
    "        #vanilla implementation of RMSprop\n",
    "        self.G = 0.9 * self.G + 0.1 * u**2  \n",
    "        self.w -= self.lr/np.sqrt(self.G + 1e-8) * u\n",
    "        return\n",
    "    \n",
    "    #this is where we generate some sample text after having fully trained our model\n",
    "    #i.e error is below some threshold\n",
    "    def sample(self):\n",
    "         #loop through recurrences - start at 1 so the 0th entry of all arrays will be an array of 0's\n",
    "        for i in range(1, self.rl+1):\n",
    "            #set input for LSTM cell, combination of input (previous output) and previous hidden state\n",
    "            self.LSTM.x = np.hstack((self.ha[i-1], self.x))\n",
    "            #run forward prop on the LSTM cell, retrieve cell state and hidden state\n",
    "            cs, hs, f, inp, c, o = self.LSTM.forwardProp()\n",
    "            #store input as vector\n",
    "            maxI = np.argmax(self.x)\n",
    "            self.x = np.zeros_like(self.x)\n",
    "            self.x[maxI] = 1\n",
    "            self.ia[i] = self.x #Use np.argmax?\n",
    "            #store cell states\n",
    "            self.ca[i] = cs\n",
    "            #store hidden state\n",
    "            self.ha[i] = hs\n",
    "            #forget gate\n",
    "            self.af[i] = f\n",
    "            #input gate\n",
    "            self.ai[i] = inp\n",
    "            #cell state\n",
    "            self.ac[i] = c\n",
    "            #output gate\n",
    "            self.ao[i] = o\n",
    "            #calculate output by multiplying hidden state with weight matrix\n",
    "            self.oa[i] = self.sigmoid(np.dot(self.w, hs))\n",
    "            #compute new input\n",
    "            maxI = np.argmax(self.oa[i])\n",
    "            newX = np.zeros_like(self.x)\n",
    "            newX[maxI] = 1\n",
    "            self.x = newX\n",
    "        #return all outputs    \n",
    "        return self.oa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    # LSTM cell (input, output, amount of recurrence, learning rate)\n",
    "    def __init__ (self, xs, ys, rl, lr):\n",
    "        #input is word length x word length\n",
    "        self.x = np.zeros(xs+ys)\n",
    "        #input size is word length + word length\n",
    "        self.xs = xs + ys\n",
    "        #output \n",
    "        self.y = np.zeros(ys)\n",
    "        #output size\n",
    "        self.ys = ys\n",
    "        #cell state intialized as size of prediction\n",
    "        self.cs = np.zeros(ys)\n",
    "        #how often to perform recurrence\n",
    "        self.rl = rl\n",
    "        #balance the rate of training (learning rate)\n",
    "        self.lr = lr\n",
    "        #init weight matrices for our gates\n",
    "        #forget gate\n",
    "        self.f = np.random.random((ys, xs+ys))\n",
    "        #input gate\n",
    "        self.i = np.random.random((ys, xs+ys))\n",
    "        #cell state\n",
    "        self.c = np.random.random((ys, xs+ys))\n",
    "        #output gate\n",
    "        self.o = np.random.random((ys, xs+ys))\n",
    "        #forget gate gradient\n",
    "        self.Gf = np.zeros_like(self.f)\n",
    "        #input gate gradient\n",
    "        self.Gi = np.zeros_like(self.i)\n",
    "        #cell state gradient\n",
    "        self.Gc = np.zeros_like(self.c)\n",
    "        #output gate gradient\n",
    "        self.Go = np.zeros_like(self.o)\n",
    "    \n",
    "    #activation function to activate our forward prop, just like in any type of neural network\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    #derivative of sigmoid to help computes gradients\n",
    "    def dsigmoid(self, x):\n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "    \n",
    "    #tanh! another activation function, often used in LSTM cells\n",
    "    #Having stronger gradients: since data is centered around 0, \n",
    "    #the derivatives are higher. To see this, calculate the derivative \n",
    "    #of the tanh function and notice that input values are in the range [0,1].\n",
    "    def tangent(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    #derivative for computing gradients\n",
    "    def dtangent(self, x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "    \n",
    "    #lets compute a series of matrix multiplications to convert our input into our output\n",
    "    def forwardProp(self):\n",
    "        f = self.sigmoid(np.dot(self.f, self.x))\n",
    "        self.cs *= f\n",
    "        i = self.sigmoid(np.dot(self.i, self.x))\n",
    "        c = self.tangent(np.dot(self.c, self.x))\n",
    "        self.cs += i * c\n",
    "        o = self.sigmoid(np.dot(self.o, self.x))\n",
    "        self.y = o * self.tangent(self.cs)\n",
    "        return self.cs, self.y, f, i, c, o\n",
    "    \n",
    "   \n",
    "    def backProp(self, e, pcs, f, i, c, o, dfcs, dfhs):\n",
    "        #error = error + hidden state derivative. clip the value between -6 and 6.\n",
    "        e = np.clip(e + dfhs, -6, 6)\n",
    "        #multiply error by activated cell state to compute output derivative\n",
    "        do = self.tangent(self.cs) * e\n",
    "        #output update = (output deriv * activated output) * input\n",
    "        ou = np.dot(np.atleast_2d(do * self.dtangent(o)).T, np.atleast_2d(self.x))\n",
    "        #derivative of cell state = error * output * deriv of cell state + deriv cell\n",
    "        dcs = np.clip(e * o * self.dtangent(self.cs) + dfcs, -6, 6)\n",
    "        #deriv of cell = deriv cell state * input\n",
    "        dc = dcs * i\n",
    "        #cell update = deriv cell * activated cell * input\n",
    "        cu = np.dot(np.atleast_2d(dc * self.dtangent(c)).T, np.atleast_2d(self.x))\n",
    "        #deriv of input = deriv cell state * cell\n",
    "        di = dcs * c\n",
    "        #input update = (deriv input * activated input) * input\n",
    "        iu = np.dot(np.atleast_2d(di * self.dsigmoid(i)).T, np.atleast_2d(self.x))\n",
    "        #deriv forget = deriv cell state * all cell states\n",
    "        df = dcs * pcs\n",
    "        #forget update = (deriv forget * deriv forget) * input\n",
    "        fu = np.dot(np.atleast_2d(df * self.dsigmoid(f)).T, np.atleast_2d(self.x))\n",
    "        #deriv cell state = deriv cell state * forget\n",
    "        dpcs = dcs * f\n",
    "        #deriv hidden state = (deriv cell * cell) * output + deriv output * output * output deriv input * input * output + deriv forget\n",
    "        #* forget * output\n",
    "        dphs = np.dot(dc, self.c)[:self.ys] + np.dot(do, self.o)[:self.ys] + np.dot(di, self.i)[:self.ys] + np.dot(df, self.f)[:self.ys] \n",
    "        #return update gradinets for forget, input, cell, output, cell state, hidden state\n",
    "        return fu, iu, cu, ou, dpcs, dphs\n",
    "            \n",
    "    def update(self, fu, iu, cu, ou):\n",
    "        #update forget, input, cell, and output gradients\n",
    "        self.Gf = 0.9 * self.Gf + 0.1 * fu**2 \n",
    "        self.Gi = 0.9 * self.Gi + 0.1 * iu**2   \n",
    "        self.Gc = 0.9 * self.Gc + 0.1 * cu**2   \n",
    "        self.Go = 0.9 * self.Go + 0.1 * ou**2   \n",
    "        \n",
    "        #update our gates using our gradients\n",
    "        self.f -= self.lr/np.sqrt(self.Gf + 1e-8) * fu\n",
    "        self.i -= self.lr/np.sqrt(self.Gi + 1e-8) * iu\n",
    "        self.c -= self.lr/np.sqrt(self.Gc + 1e-8) * cu\n",
    "        self.o -= self.lr/np.sqrt(self.Go + 1e-8) * ou\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
